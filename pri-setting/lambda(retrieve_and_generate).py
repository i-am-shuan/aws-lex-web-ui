import openai
import json
import random
import decimal 
import os
import json
import random
import decimal 
import logging
import chardet
import PyPDF2
from PyPDF2 import PdfReader
from io import BytesIO
import boto3
from urllib.parse import unquote
from botocore.exceptions import ClientError
from botocore.exceptions import BotoCoreError
import gzip
import csv



logger = logging.getLogger()
logger.setLevel(logging.INFO)

openai.api_key = os.environ['OPENAI_API']

bedrock_agent_runtime = boto3.client(
    service_name = "bedrock-agent-runtime"
)

    
def elicit_intent(intent_request, session_attributes, message):
    return {
        'sessionState': {
            'dialogAction': {
                'type': 'ElicitIntent'
            },
            'sessionAttributes': session_attributes
        },
        'messages': [ message ] if message != None else None,
        'requestAttributes': intent_request['requestAttributes'] if 'requestAttributes' in intent_request else None
    }

def elicit_slot(session_attributes, intent_name, slots, slot_to_elicit, message):
    return {
        'sessionState': {
            'dialogAction': {
                'type': 'ElicitSlot',
                'slotToElicit': slot_to_elicit,
                'intentName': intent_name
            },
            'intent': {
                'name': intent_name,
                'slots': slots,
                'state': 'InProgress'
            },
            'sessionAttributes': session_attributes
        },
        'messages': [message] if message else []
    }

def close(intent_request, session_attributes, fulfillment_state, message):
    intent_request['sessionState']['intent']['state'] = fulfillment_state
    return {
        'sessionState': {
            'sessionAttributes': session_attributes,
            'dialogAction': {
                'type': 'Close'
            },
            'intent': intent_request['sessionState']['intent']
        },
        'messages': [message],
        'sessionId': intent_request['sessionId'],
        'requestAttributes': intent_request['requestAttributes'] if 'requestAttributes' in intent_request else None
    }
    

def get_session_attributes(intent_request):
    sessionState = intent_request['sessionState']
    if 'sessionAttributes' in sessionState:
        return sessionState['sessionAttributes']
    else:
        return {}

def get_slots(intent_request):
    # 'sessionState'ì˜ 'intent'ì—ì„œ 'slots' ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    return intent_request['sessionState']['intent']['slots']
    
def get_slot(intent_request, slotName):
    # 'slots' ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    slots = get_slots(intent_request)
    
    # 'slots'ê°€ Noneì´ ì•„ë‹ˆê³ , 'slotName'ì´ 'slots' ì•ˆì— ìˆìœ¼ë©°, í•´ë‹¹ ìŠ¬ë¡¯ì´ Noneì´ ì•„ë‹Œ ê²½ìš°,
    # 'interpretedValue'ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    if slots is not None and slotName in slots:
        slot = slots[slotName]
        # ìŠ¬ë¡¯ì˜ ê°’ì´ Noneì´ ì•„ë‹ˆê³ , 'value' í‚¤ê°€ ìˆìœ¼ë©°, 'value'ê°€ Noneì´ ì•„ë‹Œ ê²½ìš° 'interpretedValue'ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        if slot is not None and 'value' in slot and slot['value'] is not None:
            return slot['value'].get('interpretedValue')
    # ìœ„ ì¡°ê±´ì— ë§ì§€ ì•ŠëŠ” ê²½ìš°, Noneì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    return None

def build_response(intent_request, session_attributes, fulfillment_state, message):
    return {
        'sessionState': {
            'sessionAttributes': session_attributes,
            'dialogAction': {
                'type': 'Close'
            },
            'intent': {
                'name': intent_request['sessionState']['intent']['name'],
                'state': fulfillment_state
            }
        },
        'messages': [message] if message else [],
        'requestAttributes': intent_request['requestAttributes'] if 'requestAttributes' in intent_request else None
    }

def retrieve(query):
    modelArn = 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-haiku-20240307-v1:0'
    # modelArn = 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-opus-20240229-v1:0'
    kbId = "RQ7PKC2IZP"
    
    prompt = f"""
    You are an AI assistant created by Anthropic to be helpful, harmless, and honest. The user has provided the following question:

    - Question: {query}

    Please provide a thoughtful and informative response to the user's question. 
    If you do not have enough information to provide a complete answer, 
    please indicate that you are unable to fully address the query and suggest ways the user could provide more details to help you assist them better. Answer in Korean.
    """
    
    try:
        response = bedrock_agent_runtime.retrieve_and_generate(
            input={
                'text': prompt,
            },
            retrieveAndGenerateConfiguration={
                'type': 'KNOWLEDGE_BASE',
                'knowledgeBaseConfiguration': {
                    'knowledgeBaseId': kbId,
                    'modelArn': modelArn
                }
            }
        )
            
        review_result = response['output']['text'].strip().lower()
        logger.info('### retrieve response: %s', review_result)
        if 'sorry' in review_result or 'ì£„ì†¡í•©ë‹ˆë‹¤' in review_result:
            response['output']['text'] = 'âš ï¸ ì£„ì†¡í•´ìš”, í•´ë‹¹ ìš”ì²­ì€ ì²˜ë¦¬í•  ìˆ˜ ì—†ì–´ìš”. ì¡°ê¸ˆ ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì‹œê±°ë‚˜ ë‹¤ë¥¸ ì§ˆë¬¸ì„ í•´ì£¼ì‹œë©´ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„ìš”.'

        return response
    except Exception as e:
        logger.error(e)
        return {'error': 'ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.', 'details': str(e)}

    
def format_response_with_citations(text_response, citations_data):
    try:
        logger.info('citations_data: %s', citations_data)
        
        # ì¶œì²˜ ì •ë³´ê°€ ì—†ì„ ê²½ìš°, ê¸°ì¡´ ì‘ë‹µì„ ê·¸ëŒ€ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
        if not citations_data:
            return str(text_response)
        
        # ì¤‘ë³µëœ (source_text, source_location) ì„¸íŠ¸ ì œê±°
        unique_citations = list(set(citations_data))
        
        # ì¶œì²˜ ì •ë³´ë¥¼ í¬í•¨í•˜ëŠ” ë¬¸ìì—´ì„ ìƒì„±í•©ë‹ˆë‹¤.
        content = str(text_response) + '<br><br> ğŸ“š <b>ì¶œì²˜</b>'
        num_citations = min(len(unique_citations), 3)  # ìµœëŒ€ 3ê°œì˜ ì¶œì²˜ë§Œ ê°€ì ¸ì˜´
        
        for i, (source_text, source_location) in enumerate(unique_citations[:3]):  # ìµœëŒ€ 3ê°œì˜ ì¶œì²˜ë§Œ ì²˜ë¦¬
            # 's3://kb-able-talk-s3/test/test.pdf' í˜•íƒœì—ì„œ 'test.pdf' ì¶”ì¶œ
            file_name = source_location.split('/')[-1]
            
            # ì¶œì²˜ í…ìŠ¤íŠ¸ê°€ 00ì ì´ìƒì¸ ê²½ìš° 00ìê¹Œì§€ë§Œ í‘œì‹œí•˜ê³  '...'ì„ ì¶”ê°€
            if len(source_text) > 15:
                source_text = source_text[:15] + '...'
            
            s3_url = generate_s3_url(source_location)
            
            # ë§í¬ ìƒì„±
            citation_string = '<br><b>[{}]</b> <a href="{}" target="\\\\_blank">{}</a> <br>({})'.format(i+1, s3_url, file_name, source_text)
            
            # ë§ˆì§€ë§‰ ì¶œì²˜ì¸ ê²½ìš°ì—ëŠ” ì‰¼í‘œë¥¼ ì¶”ê°€í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
            if i < num_citations - 1:
                citation_string += ', '
            
            content += citation_string
        
        return content
    
    except Exception as e:
        logger.error('Error in format_response_with_citations: %s', str(e))
        return str(text_response)  # ì˜ˆì™¸ ë°œìƒ ì‹œ ê¸°ì¡´ ì‘ë‹µì„ ê·¸ëŒ€ë¡œ ë°˜í™˜
    

def generate_s3_url(source_location):
    try:
        # S3 í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        s3 = boto3.client('s3')

        # source_locationì—ì„œ ë²„í‚· ì´ë¦„ê³¼ í‚¤(íŒŒì¼ ê²½ë¡œ) ì¶”ì¶œ
        bucket_name, key = source_location.replace('s3://', '').split('/', 1)

        # ì„ì‹œ URL ìƒì„±
        url = s3.generate_presigned_url(
            ClientMethod='get_object',
            Params={
                'Bucket': bucket_name,
                'Key': key
            },
            ExpiresIn=3600  # ìœ íš¨ ê¸°ê°„(ì´ˆ)
        )

        return url
    except ClientError as e:
        logger.error(e)
        return None


def extract_citation_data(response):
    citations_data = []

    # ì¸ìš© ëª©ë¡ì—ì„œ ê° ì¸ìš©ì„ ë°˜ë³µ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    if 'citations' in response and response['citations']:
        for citation in response['citations']:
            # ê° ì¸ìš©ì—ì„œ ì¶”ì¶œëœ ì°¸ì¡°ë¥¼ ë°˜ë³µ ì²˜ë¦¬í•©ë‹ˆë‹¤.
            if 'retrievedReferences' in citation:
                for reference in citation['retrievedReferences']:
                    source_text = None
                    source_location = None
                    
                    # ì¶œì²˜ í…ìŠ¤íŠ¸ë¥¼ í™•ì¸í•˜ê³  ë³€ìˆ˜ì— ì €ì¥í•©ë‹ˆë‹¤.
                    if 'content' in reference and 'text' in reference['content']:
                        source_text = reference['content']['text']
                        
                    # ì¶œì²˜ê°€ ìˆëŠ” S3 ìœ„ì¹˜ë¥¼ í™•ì¸í•˜ê³  ë³€ìˆ˜ì— ì €ì¥í•©ë‹ˆë‹¤.
                    if 'location' in reference and 's3Location' in reference['location']:
                        source_location = reference['location']['s3Location'].get('uri', '')
                        
                    if source_location and source_text:
                        citations_data.append((source_text, source_location))
                        
    logger.info('extract_citation_data: %s', citations_data)
    return citations_data


def parse_documents(csv_content):
    reader = csv.reader(csv_content.strip().split('\n'))
    document_list = []
    for row in reader:
        if len(row) == 2:
            bucket, path = row
            file_name = path.split('/')[-1].rsplit('.', 1)[0]
            document_list.append(file_name)
    return ", ".join(document_list)

    
def get_s3_inventory_data():
    # S3 í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    s3 = boto3.client('s3')

    # ì¸ë²¤í† ë¦¬ manifest íŒŒì¼ ì½ê¸°
    manifest_obj = s3.get_object(Bucket='kb-able-talk-s3', Key='metadata/kb-able-talk-s3/metadata/2024-04-23T01-00Z/manifest.json')
    manifest = json.loads(manifest_obj['Body'].read())
    
    # ì¸ë²¤í† ë¦¬ CSV íŒŒì¼ ì •ë³´ ì¶”ì¶œ
    inventory_file = manifest['files'][0]
    inventory_bucket = manifest['sourceBucket']
    inventory_key = inventory_file['key']
    
    # ì¸ë²¤í† ë¦¬ CSV íŒŒì¼ ì½ê¸°
    inventory_obj = s3.get_object(Bucket=inventory_bucket, Key=inventory_key)
    inventory_content = gzip.decompress(inventory_obj['Body'].read()).decode('utf-8')
    
    # ì¸ë²¤í† ë¦¬ CSV íŒŒì¼ ë‚´ìš© ë””ì½”ë”©
    decoded_content = '\n'.join([','.join([unquote(item) for item in line.split(',')]) for line in inventory_content.split('\n')])
    parsed_content = parse_documents(decoded_content)
    
    return parsed_content


def get_suggestion_from_metadata_os_picker(intent_request, session_attributes):
    logger.info('########## get_suggestion_from_metadata_os')

    try:
        modelArn = 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-haiku-20240307-v1:0'
        kbId = "RQ7PKC2IZP"

        prompt = f"""
        Recommend questions users can ask you based on your knowledge base. No source information is included. Answer in Korean.
        """

        response = bedrock_agent_runtime.retrieve_and_generate(
            input={
                'text': prompt
            },
            retrieveAndGenerateConfiguration={
                'type': 'KNOWLEDGE_BASE',
                'knowledgeBaseConfiguration': {
                    'knowledgeBaseId': kbId,
                    'modelArn': modelArn
                }
            }
        )

        logger.info('get_suggestion_from_metadata_os-response: %s', response)

        question_list = response['output']['text'].split('\n')[1:]  # ì²« ë²ˆì§¸ ìš”ì†Œ ì œì™¸

        list_picker_content = {
            "templateType": "ListPicker",
            "version": "1.0",
            "data": {
                "replyMessage": {
                    "title": "ì§ˆë¬¸ ì„ íƒí•´ì£¼ì„¸ìš”.",
                    "subtitle": "ì•„ë˜ ì§ˆë¬¸ ì¤‘ì—ì„œ ì„ íƒí•˜ì„¸ìš”.",
                    "imageType": "URL",
                    "imageData": "https://interactive-msg.s3-us-west-2.amazonaws.com/fruit_34.3kb.jpg",
                    "imageDescription": "ì§ˆë¬¸ ì„ íƒí•˜ê¸°"
                },
                "content": {
                    "title": "ì‚¬ìš©ìê°€ ë¬¼ì–´ë³¼ ìˆ˜ ìˆëŠ” ì§ˆë¬¸",
                    "subtitle": "ì§ˆë¬¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.",
                    "imageType": "URL",
                    "imageData": "https://interactive-msg.s3-us-west-2.amazonaws.com/fruit_34.3kb.jpg",
                    "imageDescription": "ì§ˆë¬¸ ì„ íƒí•˜ê¸°",
                    "elements": [
                        {
                            "title": question,
                            "subtitle": "",
                            "imageType": "URL",
                            "imageData": "https://interactive-message-testing.s3-us-west-2.amazonaws.com/apple_4.2kb.jpg"
                        } for question in question_list
                    ]
                }
            }
        }

        session_attributes['appContext'] = json.dumps(list_picker_content)

        return build_response(
            intent_request=intent_request,
            session_attributes=session_attributes,
            fulfillment_state="Fulfilled",
            message={
                'contentType': 'PlainText',
                'content': 'ì§ˆë¬¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.'
            }
        )

    except Exception as e:
        return build_response(
            intent_request=intent_request,
            session_attributes=session_attributes,
            fulfillment_state="Fulfilled",
            message={
                'contentType': 'PlainText',
                'content': str(e)
            }
        )


def get_suggestion_from_metadata_os(intent_request, session_attributes):
    logger.info('################ get_suggestion_from_metadata_os ################')
    try:
        modelArn = 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-haiku-20240307-v1:0'
        # modelArn = 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-opus-20240229-v1:0'
        # kbId = "JS9ZJONAQY"  # readme.txt 
        kbId = "RQ7PKC2IZP"
        
        
        # prompt = f"""
        # ë‹¹ì‹ ì´ ê°–ê³ ìˆëŠ” ì§€ì‹ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìê°€ ë‹¹ì‹ ì—ê²Œ ë¬¼ì–´ë³¼ ìˆ˜ ìˆëŠ” ì§ˆë¬¸ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”.
        # """
        
        prompt = f"""
        Recommend questions users can ask you based on your knowledge base. No source information is included. Answer in Korean.
        """
    
        response = bedrock_agent_runtime.retrieve_and_generate(
            input={
                'text': prompt
            },
            retrieveAndGenerateConfiguration={
                'type': 'KNOWLEDGE_BASE',
                'knowledgeBaseConfiguration': {
                    'knowledgeBaseId': kbId,
                    'modelArn': modelArn
                }
            }
        )
        
        content = response['output']['text'] + '<br><br>ğŸ“š í•™ìŠµ ì •ë³´: <a href="https://www.kbsec.com/go.able?linkcd=m06100004">KBì¦ê¶Œ í™ˆí˜ì´ì§€ ì•½ê´€/ìœ ì˜ì‚¬í•­</a>'
        logger.info('get_suggestion_from_metadata_os-response: %s', response)
        app_context = {
            "altMessages": {
                "markdown": content
            }
        }
        session_attributes['appContext'] = json.dumps(app_context)
        
        return build_response(
            intent_request=intent_request,
            session_attributes=session_attributes,
            fulfillment_state="Fulfilled",
            message={
                'contentType': 'PlainText',
                'content': content
            }
        )
    except Exception as e:
        return build_response(
            intent_request=intent_request,
            session_attributes=session_attributes,
            fulfillment_state="Fulfilled",
            message={
                'contentType': 'PlainText',
                'content': str(e)
            }
        )
       

def get_suggestion_from_metadata_os_btn(intent_request, session_attributes):
    logger.info('########## get_suggestion_from_metadata_os')
    
    try:
        modelArn = 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-haiku-20240307-v1:0'
        # modelArn = 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-opus-20240229-v1:0'
        # kbId = "JS9ZJONAQY"  # readme.txt 
        kbId = "RQ7PKC2IZP"
        
        
        # prompt = f"""
        # ë‹¹ì‹ ì´ ê°–ê³ ìˆëŠ” ì§€ì‹ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìê°€ ë‹¹ì‹ ì—ê²Œ ë¬¼ì–´ë³¼ ìˆ˜ ìˆëŠ” ì§ˆë¬¸ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”.
        # """
        
        prompt = f"""
        Recommend questions users can ask you based on your knowledge base. No source information is included. Answer in Korean.
        """
    
        response = bedrock_agent_runtime.retrieve_and_generate(
            input={
                'text': prompt
            },
            retrieveAndGenerateConfiguration={
                'type': 'KNOWLEDGE_BASE',
                'knowledgeBaseConfiguration': {
                    'knowledgeBaseId': kbId,
                    'modelArn': modelArn
                }
            }
        )
        
        logger.info('get_suggestion_from_metadata_os-response: %s', response)
        
        question_list = response['output']['text'].split('\n')
        buttons = []
        for question in question_list[1:]:  # ì²« ë²ˆì§¸ ìš”ì†ŒëŠ” ì œì™¸
            if question.strip():
                buttons.append({
                    'text': question.strip().replace('- ', ''),
                    'value': question.strip().replace('- ', '')
                })
        
        content = 'ì‚¬ìš©ìê°€ ì§ˆë¬¸í•  ìˆ˜ ìˆëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤. ë²„íŠ¼ì„ í´ë¦­í•´ ë³´ì„¸ìš”:<br><br>'
        content += 'ğŸ“š í•™ìŠµ ì •ë³´: <a href="https://www.kbsec.com/go.able?linkcd=m06100004">KBì¦ê¶Œ í™ˆí˜ì´ì§€ ì•½ê´€/ìœ ì˜ì‚¬í•­</a>'
        
        logger.info('########## question_list: %s', question_list)
        logger.info('########## question: %s', question)
        logger.info('########## buttons: %s', buttons)
        
        app_context = {
            "altMessages": {
                "markdown": content
            },
            "buttons": buttons
        }
        
        session_attributes['appContext'] = json.dumps(app_context)
        logger.info('########## appContext: %s', session_attributes['appContext'])
        
        return build_response(
            intent_request=intent_request,
            session_attributes=session_attributes,
            fulfillment_state="Fulfilled",
            message={
                'contentType': 'PlainText',
                'content': content
            }
        )
    except Exception as e:
        return build_response(
            intent_request=intent_request,
            session_attributes=session_attributes,
            fulfillment_state="Fulfilled",
            message={
                'contentType': 'PlainText',
                'content': str(e)
            }
        )
       

def review_query_with_metadata_os(query):
    try:
        modelArn = 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-haiku-20240307-v1:0'
        # modelArn = 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-opus-20240229-v1:0'
        # kbId = "JS9ZJONAQY"  # readme.txt 
        kbId = "RQ7PKC2IZP"
        
        # TODO Shuan metadata ìë™í™” ######
        # AS-IS: ì§€ê¸ˆì€ ìˆ˜ë™ìœ¼ë¡œ readme íŒŒì¼ì„ ë“±ë¡í•´ë†¨ìŒ - S3:1, OS:2
        # s3://kb-able-talk-s3/readme.txt 
        # [lambda] metadata íŒŒì¼ ì½ê³  > [lambda] csv.zp íŒŒì¼ íŒŒì‹± to text > [lambda] S3 readme.txt ì—…ë°ì´íŠ¸ > S3 ì´ë²¤íŠ¸ íŠ¸ë¦¬ê±°
        # [lambda] readme íŒŒì¼ ì½ê³    > [lambda] ì„ë² ë”© (JS9ZJONAQY)
        # promptì— metadataë¥¼ ë…¹ì´ë ¤ê³  í–ˆìœ¼ë‚˜, ì œí•œëœ INPUT lengthë¡œ metadata ì •ë³´ë¥¼ ë°”ë¼ë³´ëŠ” OSë¥¼ ë³„ë„ë¡œ ë‘ 
        # ê°œì„ ì‚¬í•­: apië¥¼ í˜¸ì¶œí• ë•Œ documentë¥¼ ì²¨ë¶€í•  ìˆ˜ ìˆê±°ë‚˜, metadata urlì„ ì°¸ì¡°í•  ìˆ˜ ìˆê²Œ í”„ë¡¬í”„íŒ…ì´ ëœë‹¤ë©´- ë³„ë„ì˜ ì„ë² ë”©ê³¼ OSëŠ” í•„ìš”ì—†ìŒ ######
        
        # prompt = f"""
        # ì§ˆë¬¸: "{query}"
        # ì´ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ìˆëŠ”ì§€ ê²€í† í•´ ì£¼ì„¸ìš”. ê°€ëŠ¥í•˜ë‹¤ë©´ ê´€ë ¨ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì„ ì¤€ë¹„í•˜ê³ , ë¶ˆê°€ëŠ¥í•  ê²½ìš° 'ì£„ì†¡í•©ë‹ˆë‹¤'ë¼ê³  ì‘ë‹µí•´ ì£¼ì„¸ìš”.
        # """
        
        prompt = f"""
        question: "{query}"
        Please consider if you can provide an answer to this question. If possible, prepare a response based on relevant information, and if not possible, respond with 'sorry'.
        No source information is included.
        """
    
        logger.info('prompt: %s', prompt)
        response = bedrock_agent_runtime.retrieve_and_generate(
            input={
                'text': prompt
            },
            retrieveAndGenerateConfiguration={
                'type': 'KNOWLEDGE_BASE',
                'knowledgeBaseConfiguration': {
                    'knowledgeBaseId': kbId,
                    'modelArn': modelArn
                }
            }
        )
        
        review_result = response['output']['text'].strip().lower()
        logger.info('review_result response: %s', review_result)
        # todo shuan
        # [INFO]	2024-04-26T01:27:34.694Z	3841859b-6487-4e7b-ba3d-1c88c3c473d0	review_result response: the search results do not contain specific information about financial product fees and costs. the results mostly contain various financial service agreements and terms of use, but do not provide a comprehensive overview of fees and costs associated with different financial products. without more detailed information, i cannot provide a satisfactory answer to the question about financial product fees and costs.

        
        # if 'sorry' in review_result or 'do not contain' in review_result or 'ì£„ì†¡í•©ë‹ˆë‹¤' in review_result or 'ê²€ìƒ‰ ê²°ê³¼' in review_result or 'ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤' in review_result:
        if any(phrase in review_result for phrase in ['sorry', 'do not contain', 'ì£„ì†¡í•©ë‹ˆë‹¤', 'ê²€ìƒ‰ ê²°ê³¼', 'ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤']):
            logger.info('[review_query_with_metadata_os] can_answer: False')
            return {'can_answer': False}
        else:
            return {'can_answer': True}
    except Exception as e:
        logger.error('Exception: %s', {str(e)})
        # return {'can_answer': False, 'message': f'ì§ˆë¬¸ ê²€í†  ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}
        return {'can_answer': False}
    
def handle_rag(intent_request, content_data, session_attributes):
    try:
        source_text = None
        source_location = None
        
        if not content_data:
            return elicit_slot(
                session_attributes=session_attributes,
                intent_name='Reception',
                slots=get_slots(intent_request),
                slot_to_elicit='ContentData',
                message={
                    'contentType': 'PlainText',
                    'content': 'âš ï¸ ì´ìš©ì•½ê´€ ë° ìœ ì˜ì‚¬í•­ì— ëŒ€í•œ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.'
                }
            )
        
        doc_list = get_s3_inventory_data() ## TODO metadata íŒŒì‹± ê²°ê³¼ - ì•„ì§ ì‚¬ìš©ì€ ì•ˆí•¨
        
        # ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µë³€ ê°€ëŠ¥í•œì§€ ê²€í†  ìš”ì²­
        review_response = review_query_with_metadata_os(content_data)
        
        if review_response['can_answer']:
            response = retrieve(content_data)
            logger.info('retrieve-response: %s', response)
            citations_data = extract_citation_data(response)
            content = format_response_with_citations(response['output']['text'], citations_data)
            
            app_context = {
                "altMessages": {
                    "markdown": content
                }
            }
            session_attributes['appContext'] = json.dumps(app_context)
            
            return build_response(
                intent_request=intent_request,
                session_attributes=session_attributes,
                fulfillment_state="Fulfilled",
                message={
                    'contentType': 'PlainText',
                    'content': content
                }
            )
        else:
            return fallbackIntent(intent_request, content_data, session_attributes)
        
    except Exception as e:
        logger.error('Exception: %s', e, exc_info=True)
        return fallbackIntent(intent_request, content_data, session_attributes)

def fallbackIntent(intent_request, content_data, session_attributes):
    try:
        logger.info('fallbackIntent-content_data: %s', content_data)
        response = retrieve(content_data)
        
        app_context = {
            "altMessages": {
                "markdown": response['output']['text']
            }
        }
        session_attributes['appContext'] = json.dumps(app_context)
    
        return build_response(
            intent_request=intent_request,
            session_attributes=session_attributes,
            fulfillment_state="Fulfilled",
            message={
                'contentType': 'PlainText',
                'content': response['output']['text']
            }
        )
    except Exception as e:
        return build_response(
            intent_request=intent_request,
            session_attributes=session_attributes,
            fulfillment_state="Fulfilled",
            message={
                'contentType': 'PlainText',
                'content': str(e)
            }
        )

def handle_exception(e, intent_request, session_attributes):
    """
    ì´ í•¨ìˆ˜ëŠ” ì˜ˆì™¸ ìƒí™©ì´ ë°œìƒí–ˆì„ ë•Œ ì‚¬ìš©ìì—ê²Œ ì ì ˆí•œ ì‘ë‹µì„ ì œê³µí•©ë‹ˆë‹¤.
    """
    logger.error('Exception: %s', e, exc_info=True)
    error_message = f'ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”. ì˜¤ë¥˜ ë‚´ìš©: {str(e)}'

    # ì˜¤ë¥˜ ë©”ì‹œì§€ë¡œ ì‚¬ìš©ìì—ê²Œ ì‘ë‹µì„ ë³´ëƒ…ë‹ˆë‹¤.
    return build_response(
        intent_request=intent_request,
        session_attributes=session_attributes,
        fulfillment_state="Failed",
        message={
            'contentType': 'PlainText',
            'content': error_message
        }
    )

def Reception(intent_request):
    try:
        logger.info('intent_request: %s', intent_request)
        session_attributes = get_session_attributes(intent_request)
        content = intent_request['inputTranscript']
        
        if content == 'ì‚¬ìš© ì˜ˆì‹œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.':
            return get_suggestion_from_metadata_os(intent_request, session_attributes)
        
        
        # 'ë²ˆì—­' íƒœìŠ¤í¬ì— ëŒ€í•œ ìŠ¬ë¡¯ ê°’ ê°€ì ¸ì˜¤ê¸°
        # translation_language = get_slot(intent_request, 'TranslationLanguage') if task_type == 'ë²ˆì—­' else None
        
        # ê° íƒœìŠ¤í¬ ìœ í˜•ë³„ë¡œ ì²˜ë¦¬í•  í•¸ë“¤ëŸ¬ í•¨ìˆ˜ë¥¼ ì‚¬ì „ì— ë§¤í•‘
        # task_handlers = {
        #     'ìš”ì•½': handle_summary,
        #     'ë²ˆì—­': handle_translation,
        #     'ë¬¸êµ¬ìƒì„±': handle_gen_text,
        #     'sql': handle_gen_sql,
        #     'ê¸°íƒ€': handle_etc,
        #     'ë¬¸ì„œë¦¬ë·°': handle_doc_summary,
        #     'rag': handle_rag
        # }
        
        # return task_handlers[task_type](intent_request, content, session_attributes)
        
        
        
        return handle_rag(intent_request, content, session_attributes)
    
    except Exception as e:
        logger.error(f"Exception occurred: {str(e)}")
        return fallbackIntent(intent_request, content, session_attributes)


def dispatch(intent_request):
    intent_name = intent_request['sessionState']['intent']['name']
    content = get_slot(intent_request, 'ContentData')
    session_attributes = get_session_attributes(intent_request)
    
    return Reception(intent_request)



def lambda_handler(event, context):
    try:
        logger.info('Event: %s', json.dumps(event))
        
        response = dispatch(event)
        return response
    except Exception as e:
        return handle_exception(e, event, get_session_attributes(event))


