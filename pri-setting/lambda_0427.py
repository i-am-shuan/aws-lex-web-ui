import openai
import json
import random
import decimal 
import os
import json
import random
import decimal 
import logging
import boto3

logger = logging.getLogger()
logger.setLevel(logging.INFO)

openai.api_key = os.environ['OPENAI_API']

# Amazon S3 í´ë¼ì´ì–¸íŠ¸ ìƒì„±
s3 = boto3.client('s3')

# Shuan
bedrock_agent_runtime = boto3.client(
    service_name = "bedrock-agent-runtime"
)

# ì‚¬ì‹¤ ê¸°ë°˜ íƒœìŠ¤í¬ì—ëŠ” Haikuë¥¼, ì°½ì˜ì  ìƒì„± íƒœìŠ¤í¬ì—ëŠ” Sonnetì„ ì‚¬ìš©
def retrieve(query, kbId):
    # modelArn = 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:1'
    #modelArn = 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0'
    modelArn = 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-haiku-20240307-v1:0'
    
    return bedrock_agent_runtime.retrieve_and_generate(
        input={
            'text': query,
        },
        retrieveAndGenerateConfiguration={
            'type': 'KNOWLEDGE_BASE',
            'knowledgeBaseConfiguration': {
                'knowledgeBaseId': kbId,
                'modelArn': modelArn,
            }
        }
    )

def extract_citation_data(response, llm):
    source_text = ""
    source_location = ""

    if llm == 'claude':
        # 'citations' í‚¤ì˜ ì¡´ì¬ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ê³ , ê´€ë ¨ ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        if 'citations' in response and response['citations']:
            first_citation = response['citations'][0]

            # 'retrievedReferences'ì˜ ì¡´ì¬ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ê³ , ì¶œì²˜ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
            if 'retrievedReferences' in first_citation and first_citation['retrievedReferences']:
                first_reference = first_citation['retrievedReferences'][0]

                # ì¶œì²˜ í…ìŠ¤íŠ¸ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ë³€ìˆ˜ì— ì €ì¥í•©ë‹ˆë‹¤.
                if 'content' in first_reference and 'text' in first_reference['content']:
                    source_text = first_reference['content']['text']

                # ì¶œì²˜ê°€ ìˆëŠ” S3 ìœ„ì¹˜ë¥¼ í™•ì¸í•˜ê³  ë³€ìˆ˜ì— ì €ì¥í•©ë‹ˆë‹¤.
                if 'location' in first_reference and 's3Location' in first_reference['location']:
                    source_location = first_reference['location']['s3Location'].get('uri', '')

    # ë‹¤ë¥¸ LLMì˜ ê²½ìš° ë‹¤ë¥¸ ì²˜ë¦¬ë¥¼ í•  ìˆ˜ ìˆë„ë¡ ë¶„ê¸°ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
    # ì˜ˆë¥¼ ë“¤ì–´:
    elif llm == 'other_llm':
        # ë‹¤ë¥¸ LLMì— ëŒ€í•œ ì²˜ë¦¬ ë¡œì§
        pass

    return source_text, source_location


## TODO Shuan
def handle_rag(intent_request, content_data, session_attributes):
    if not content_data:
        return elicit_slot(
            session_attributes=session_attributes,
            intent_name='Reception',
            slots=get_slots(intent_request),
            slot_to_elicit='ContentData',
            message={
                'contentType': 'PlainText',
                'content': 'ğŸ”–ì˜ˆì‹œ: 2016ë…„ë„ ì¶œìƒì•„ ìˆ˜ì™€ ë…¸ë…„ ì¸êµ¬ì˜ ìˆ˜ë¥¼ ì•Œë ¤ì¤˜.'
            }
        )
    
    response = retrieve(content_data, "CVGYCPENVU")
    text_response = response['output']['text'] if 'output' in response and 'text' in response['output'] else 'No response found.'
    source_text, source_location = extract_citation_data(response, 'claude')

    # logger.info('response: %s', response)
    logger.info('text_response: %s', text_response)
    logger.info('source_text: %s', source_text)
    logger.info('source_location: %s', source_location)
    content = "{}\n\n(ì¶œì²˜: {})".format(text_response, source_location) if source_location else text_response


    return build_response(
        intent_request=intent_request,
        session_attributes=session_attributes,
        fulfillment_state="Fulfilled",
        message={
            'contentType': 'PlainText',
            'content': content
        }
    )
    
    
    
#######################################################


def elicit_intent(intent_request, session_attributes, message):
    return {
        'sessionState': {
            'dialogAction': {
                'type': 'ElicitIntent'
            },
            'sessionAttributes': session_attributes
        },
        'messages': [ message ] if message != None else None,
        'requestAttributes': intent_request['requestAttributes'] if 'requestAttributes' in intent_request else None
    }

def elicit_slot(session_attributes, intent_name, slots, slot_to_elicit, message):
    return {
        'sessionState': {
            'dialogAction': {
                'type': 'ElicitSlot',
                'slotToElicit': slot_to_elicit,
                'intentName': intent_name
            },
            'intent': {
                'name': intent_name,
                'slots': slots,
                'state': 'InProgress'
            },
            'sessionAttributes': session_attributes
        },
        'messages': [message] if message else []
    }

def close(intent_request, session_attributes, fulfillment_state, message):
    intent_request['sessionState']['intent']['state'] = fulfillment_state
    return {
        'sessionState': {
            'sessionAttributes': session_attributes,
            'dialogAction': {
                'type': 'Close'
            },
            'intent': intent_request['sessionState']['intent']
        },
        'messages': [message],
        'sessionId': intent_request['sessionId'],
        'requestAttributes': intent_request['requestAttributes'] if 'requestAttributes' in intent_request else None
    }
    

def get_session_attributes(intent_request):
    sessionState = intent_request['sessionState']
    if 'sessionAttributes' in sessionState:
        return sessionState['sessionAttributes']
    else:
        return {}

def get_slots(intent_request):
    # 'sessionState'ì˜ 'intent'ì—ì„œ 'slots' ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    return intent_request['sessionState']['intent']['slots']
    
def get_slot(intent_request, slotName):
    # 'slots' ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    slots = get_slots(intent_request)
    
    # 'slots'ê°€ Noneì´ ì•„ë‹ˆê³ , 'slotName'ì´ 'slots' ì•ˆì— ìˆìœ¼ë©°, í•´ë‹¹ ìŠ¬ë¡¯ì´ Noneì´ ì•„ë‹Œ ê²½ìš°,
    # 'interpretedValue'ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    if slots is not None and slotName in slots:
        slot = slots[slotName]
        # ìŠ¬ë¡¯ì˜ ê°’ì´ Noneì´ ì•„ë‹ˆê³ , 'value' í‚¤ê°€ ìˆìœ¼ë©°, 'value'ê°€ Noneì´ ì•„ë‹Œ ê²½ìš° 'interpretedValue'ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        if slot is not None and 'value' in slot and slot['value'] is not None:
            return slot['value'].get('interpretedValue')
    # ìœ„ ì¡°ê±´ì— ë§ì§€ ì•ŠëŠ” ê²½ìš°, Noneì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    return None

def build_response(intent_request, session_attributes, fulfillment_state, message):
    return {
        'sessionState': {
            'sessionAttributes': session_attributes,
            'dialogAction': {
                'type': 'Close'
            },
            'intent': {
                'name': intent_request['sessionState']['intent']['name'],
                'state': fulfillment_state
            }
        },
        'messages': [message] if message else [],
        'requestAttributes': intent_request['requestAttributes'] if 'requestAttributes' in intent_request else None
    }



def handle_doc_summary(intent_request, session_attributes):
    # ì„œë¹„ìŠ¤ ì¤€ë¹„ì¤‘ì¸ ìƒíƒœ ë©”ì‹œì§€
    service_unavailable_message = {
        'contentType': 'PlainText',
        'content': 'ì„œë¹„ìŠ¤ ì¤€ë¹„ì¤‘ì…ë‹ˆë‹¤.'
    }
    # 'Close' dialog actionì„ ì‚¬ìš©í•˜ì—¬ ë©”ì‹œì§€ ì „ë‹¬
    return {
        'dialogAction': {
            'type': 'Close',
            'fulfillmentState': 'Fulfilled',
            'message': service_unavailable_message
        },
        'sessionAttributes': session_attributes
    }    
    
###############################################################
# TODO    
def handle_doc_summary2(intent_request, session_attributes):
    # ì„¸ì…˜ ì†ì„±ì—ì„œ s3 ê²½ë¡œì™€ íŒŒì¼ ì´ë¦„ì„ ì¶”ì¶œ
    s3_path = session_attributes.get('s3Path')
    file_name = session_attributes.get('fileName')

    # íŒŒì¼ ì •ë³´ê°€ ì—†ìœ¼ë©´ ì‚¬ìš©ìì—ê²Œ ë¬¸ì„œ ì—…ë¡œë“œ ìš”ì²­
    if not s3_path or not file_name:
        return elicit_slot(
            session_attributes=session_attributes,
            intent_name=intent_request['sessionState']['intent']['name'],
            slots=get_slots(intent_request),
            slot_to_elicit='Document',
            message={
                'contentType': 'PlainText',
                'content': 'ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.'
            }
        )

    # s3 ê²½ë¡œì—ì„œ ë²„í‚· ì´ë¦„ê³¼ í‚¤ ì¶”ì¶œ
    bucket = s3_path.split('/')[2]
    key = '/'.join(s3_path.split('/')[3:])
    
    try:
        # S3ì—ì„œ íŒŒì¼ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
        response = s3.get_object(Bucket=bucket, Key=key)
    except s3.exceptions.NoSuchKey:
        logger.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        # NoSuchKey ì˜¤ë¥˜ì— ëŒ€í•œ ì‚¬ìš©ì ì¹œí™”ì ì¸ ë©”ì‹œì§€ë¡œ ì‘ë‹µ
        return close(
            intent_request,
            session_attributes,
            'Failed',
            {'contentType': 'PlainText', 'content': 'ìš”ì²­í•˜ì‹  ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ëª…ì„ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.'}
        )
    except s3.exceptions.ClientError as e:
        logger.error(f"S3 í´ë¼ì´ì–¸íŠ¸ ì—ëŸ¬: {e}")
        if e.response['Error']['Code'] == 'AccessDenied':
            # ì ‘ê·¼ ê±°ë¶€ ì˜¤ë¥˜ì— ëŒ€í•œ ì²˜ë¦¬
            return close(
                intent_request,
                session_attributes,
                'Failed',
                {'contentType': 'PlainText', 'content': 'ë¬¸ì„œì— ì ‘ê·¼í•  ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤. ê¶Œí•œì„ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.'}
            )
        else:
            # ê¸°íƒ€ S3 í´ë¼ì´ì–¸íŠ¸ ì˜¤ë¥˜ì— ëŒ€í•œ ì²˜ë¦¬
            return close(
                intent_request,
                session_attributes,
                'Failed',
                {'contentType': 'PlainText', 'content': 'ë¬¸ì„œë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë™ì•ˆ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ ì£¼ì„¸ìš”.'}
            )
    except Exception as e:
        logger.error(f"ì˜ˆì™¸ ì²˜ë¦¬: {e}")
        # ì˜ˆìƒì¹˜ ëª»í•œ ì˜ˆì™¸ ì²˜ë¦¬
        return close(
            intent_request,
            session_attributes,
            'Failed',
            {'contentType': 'PlainText', 'content': 'ë¬¸ì„œ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'}
        )

    # ë¬¸ì„œ ë‚´ìš© ì½ê¸° ì„±ê³µ
    content_data = response['Body'].read().decode('utf-8')

    try:
        # OpenAI GPT-3ì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œ ë‚´ìš© ìš”ì•½
        summary_response = openai.Completion.create(
            model="text-davinci-003",
            prompt=content_data  # ìš”ì•½ ì§€ì‹œë¬¸ì„ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€í•˜ì—¬ ë” ë‚˜ì€ ìš”ì•½ì„ ì–»ì„ ìˆ˜ ìˆìŒ
        )

        # ìš”ì•½ëœ ë‚´ìš© ì¶”ì¶œ
        summary = summary_response.choices[0].text.strip()

        # Lexë¡œ ìš”ì•½ëœ ë‚´ìš© ë°˜í™˜
        return build_response(
            intent_request,
            session_attributes,
            'Fulfilled',
            {'contentType': 'PlainText', 'content': summary}
        )
    except s3.exceptions.NoSuchKey:
        logger.error("ì§€ì •ëœ í‚¤ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return close(
            intent_request,
            session_attributes,
            'Failed',
            {'contentType': 'PlainText', 'content': 'ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¬¸ì„œë¥¼ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.'}
        )
    except Exception as e:
        # ë‹¤ë¥¸ ì˜ˆì™¸ë“¤ ì²˜ë¦¬
        logger.error(f"ì˜ˆì™¸ ë°œìƒ: {e}")
        return close(
            intent_request,
            session_attributes,
            'Failed',
            {'contentType': 'PlainText', 'content': 'ë¬¸ì„œë¥¼ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'}
        )

###############################################################

def handle_summary(intent_request, content_data, session_attributes):
    if not content_data:
        return elicit_slot(
            session_attributes=session_attributes,
            intent_name='Reception',
            slots=get_slots(intent_request),
            slot_to_elicit='ContentData',
            message={
                'contentType': 'PlainText',
                'content': 'ìš”ì•½í•  ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”:'
            }
        )
    
    # ìš”ì•½í•  ë‚´ìš©ì´ ìˆëŠ” ê²½ìš°, ìš”ì•½ ìˆ˜í–‰
    prompt = [{"role": "system", "content": "ë‹¤ìŒ ë‚´ìš©ì„ ìš”ì•½í•´ì£¼ì„¸ìš”."}, 
                      {"role": "user", "content": content_data}]
    llm_response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=prompt
    )

    # ìš”ì•½ëœ ë‚´ìš© ì¶”ì¶œ
    response = llm_response.choices[0].message.content

    # ìš”ì•½ëœ ë‚´ìš©ìœ¼ë¡œ ì‘ë‹µ ë©”ì‹œì§€ êµ¬ì„± í›„ ë°˜í™˜
    return build_response(
        intent_request=intent_request,
        session_attributes=session_attributes,
        fulfillment_state="Fulfilled",
        message={
            'contentType': 'PlainText',
            'content': response
        }
    )

def get_translation_direction(translation_language):
    language_lower = translation_language.lower()
    if language_lower in ["korean", "í•œêµ­ì–´", "í•œê¸€"]:
        return "to Korean"
    elif language_lower in ["english", "ì˜ì–´"]:
        return "to English"
    elif language_lower in ["japanese", "ì¼ë³¸ì–´", "ì¼ë³¸"]:
        return "to Japanese"
    else:
        return "to English"
    
def handle_translation(intent_request, content_data, translation_language, session_attributes):
    # ë²ˆì—­í•˜ë ¤ëŠ” ì–¸ì–´ê°€ ìœ íš¨í•œì§€ ê²€ì‚¬í•©ë‹ˆë‹¤.
    valid_languages = ["ì˜ì–´", "í•œê¸€", "ì¼ë³¸ì–´", "English", "Korean", "Japanese"]
    
    if not translation_language or translation_language not in valid_languages:
        # ìœ íš¨í•˜ì§€ ì•Šì€ ê²½ìš°, ì‚¬ìš©ìì—ê²Œ TranslationLanguage ìŠ¬ë¡¯ì„ ë‹¤ì‹œ ìš”ì²­í•©ë‹ˆë‹¤.
        return elicit_slot(
            session_attributes=session_attributes,
            intent_name='Reception',
            slots=get_slots(intent_request),
            slot_to_elicit='TranslationLanguage',
            message={
                'contentType': 'PlainText',
                'content': 'ì–´ë–¤ ì–¸ì–´ë¡œ ë²ˆì—­í• ê¹Œìš”? (ì˜ì–´, í•œê¸€, ì¼ë³¸ì–´)'
            }
        ) 
    
    # ë²ˆì—­í•  ë‚´ìš©ì´ ì—†ìœ¼ë©´ ì‚¬ìš©ìì—ê²Œ ìš”ì²­í•©ë‹ˆë‹¤.
    if not content_data:
        return elicit_slot(
            session_attributes=session_attributes,
            intent_name='Reception',
            slots=get_slots(intent_request),
            slot_to_elicit='ContentData',
            message={
                'contentType': 'PlainText',
                'content': 'ë²ˆì—­í•  ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”:'
            }
        )
    
    translation_direction = get_translation_direction(translation_language)
    prompt = [
        {"role": "system", "content": f"Please translate the following content {translation_direction}."},
        {"role": "user", "content": content_data}
    ]
    
    llm_response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=prompt
    )

    response = llm_response.choices[0].message.content

    return build_response(
        intent_request=intent_request,
        session_attributes=session_attributes,
        fulfillment_state="Fulfilled",
        message={
            'contentType': 'PlainText',
            'content': response
        }
    )

def handle_gen_text(intent_request, content_data, session_attributes):
    if not content_data:
        return elicit_slot(
            session_attributes=session_attributes,
            intent_name='Reception',
            slots=get_slots(intent_request),
            slot_to_elicit='ContentData',
            message={
                'contentType': 'PlainText',
                'content': 'ìš”êµ¬ì‚¬í•­ì„ ì•Œë ¤ì£¼ì„¸ìš”. ğŸ”–ì˜ˆì‹œ: KBì¦ê¶Œì˜ VIPê³ ê°ì„ ëŒ€ìƒìœ¼ë¡œ ê°ì‚¬ ì¸ì‚¬ ë©”ì„¸ì§€ë¥¼ ì‘ì„±í•´ì¤˜.'
            }
        )
    
    prompt = [{"role": "system", "content": "ë‹¤ìŒ ë‚´ìš©ìœ¼ë¡œ ë¬¸êµ¬ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”. ì ì ˆí•œ ì´ëª¨ì§€ë„ ì‚¬ìš©í•´ì£¼ì„¸ìš”."}, 
                      {"role": "user", "content": content_data}]
    llm_response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=prompt
    )

    response = llm_response.choices[0].message.content

    return build_response(
        intent_request=intent_request,
        session_attributes=session_attributes,
        fulfillment_state="Fulfilled",
        message={
            'contentType': 'PlainText',
            'content': response
        }
    )

def handle_gen_sql(intent_request, content_data, session_attributes):
    if not content_data:
        return elicit_slot(
            session_attributes=session_attributes,
            intent_name='Reception',
            slots=get_slots(intent_request),
            slot_to_elicit='ContentData',
            message={
                'contentType': 'PlainText',
                'content': 'ìš”êµ¬ì‚¬í•­ì„ ì•Œë ¤ì£¼ì„¸ìš”. ğŸ”–ì˜ˆì‹œ: ì‹í’ˆì˜ ì •ë³´ë¥¼ ë‹´ì€ í…Œì´ë¸”ê³¼ ì‹í’ˆì˜ ì£¼ë¬¸ ì •ë³´ë¥¼ ë‹´ì€ í…Œì´ë¸”ì´ ìˆìŠµë‹ˆë‹¤. í…Œì´ë¸”ì—ì„œ ìƒì‚°ì¼ìê°€ 2024ë…„ 1ì›”ì¸ ì‹í’ˆë“¤ì˜ ì´ë§¤ì¶œì„ ì¡°íšŒí•˜ëŠ” SQLë¬¸ì„ ì‘ì„±í•´ì£¼ì„¸ìš”. ì´ë•Œ ê²°ê³¼ëŠ” ì´ë§¤ì¶œì„ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬í•´ì£¼ì‹œê³  ì´ë§¤ì¶œì´ ê°™ë‹¤ë©´ ì‹í’ˆ IDë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬í•´ì£¼ì„¸ìš”.'
            }
        )
    
    prompt = [{"role": "system", "content": "ë‹¹ì‹ ì€ ê²½ë ¥ 15ë…„ì°¨ Database Administratorì…ë‹ˆë‹¤. ë‹¤ìŒì˜ ë‚´ìš©ìœ¼ë¡œ ì˜¬ë°”ë¥´ê²Œ ë™ì‘í•˜ëŠ” SQLì„ ì‘ì„±í•´ì£¼ì„¸ìš”. ê·¸ë¦¬ê³  ì‘ì„±í•œ SQLì— ëŒ€í•´ ê°„ëµí•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."}, 
                      {"role": "user", "content": content_data}]
    llm_response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=prompt
    )

    response = llm_response.choices[0].message.content

    return build_response(
        intent_request=intent_request,
        session_attributes=session_attributes,
        fulfillment_state="Fulfilled",
        message={
            'contentType': 'PlainText',
            'content': response
        }
    )

def handle_etc(intent_request, content_data, session_attributes):
    if not content_data:
        return elicit_slot(
            session_attributes=session_attributes,
            intent_name='Reception',
            slots=get_slots(intent_request),
            slot_to_elicit='ContentData',
            message={
                'contentType': 'PlainText',
                'content': 'ì–´ë–¤ ê²ƒì„ ë„ì™€ë“œë¦´ê¹Œìš”? ğŸ”–ì˜ˆì‹œ: ì €ë…ì— ë¨¹ëŠ” ì‚¬ê³¼ëŠ” ëª¸ì— í•´ë¡œìš´ê°€ìš”?'
            }
        )
    
    prompt = [{"role": "system", "content": "ë„ˆëŠ” ì‚¬ëŒë“¤ì—ê²Œ ë„ì›€ì´ ë˜ëŠ” ì¡°ìˆ˜ì•¼. ì§ˆë¬¸ì— ëŒ€í•´ í™•ì¸í•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì¤˜."}, 
                      {"role": "user", "content": content_data}]
    llm_response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=prompt
    )

    response = llm_response.choices[0].message.content

    return build_response(
        intent_request=intent_request,
        session_attributes=session_attributes,
        fulfillment_state="Fulfilled",
        message={
            'contentType': 'PlainText',
            'content': response
        }
    )

def Reception(intent_request):
    try:
        logger.info('intent_request: %s', intent_request)
        
        # ëŒ€í™” ìƒíƒœì™€ ìŠ¬ë¡¯ ê°’ì„ ê°€ì ¸ì˜´
        session_attributes = get_session_attributes(intent_request)
        task_type = get_slot(intent_request, 'TaskType').lower()
        content = get_slot(intent_request, 'ContentData')
        
        # 'ë²ˆì—­' íƒœìŠ¤í¬ì— ëŒ€í•œ ìŠ¬ë¡¯ ê°’ ê°€ì ¸ì˜¤ê¸°
        translation_language = get_slot(intent_request, 'TranslationLanguage') if task_type == 'ë²ˆì—­' else None
        
        
        # ê° íƒœìŠ¤í¬ ìœ í˜•ë³„ë¡œ ì²˜ë¦¬í•  í•¸ë“¤ëŸ¬ í•¨ìˆ˜ë¥¼ ì‚¬ì „ì— ë§¤í•‘
        task_handlers = {
            'ìš”ì•½': handle_summary,
            'ë¬¸ì„œë¦¬ë·°': handle_doc_summary,
            'ë²ˆì—­': handle_translation,
            'ë¬¸êµ¬ìƒì„±': handle_gen_text,
            'sql': handle_gen_sql,
            'ê¸°íƒ€': handle_etc,
            'rag': handle_rag
        }
            
        if task_type == 'ë²ˆì—­':
            return task_handlers[task_type](intent_request, content, translation_language, session_attributes)
        elif task_type == 'ë¬¸ì„œë¦¬ë·°':
            return task_handlers[task_type](intent_request, session_attributes)
        else:
            return task_handlers[task_type](intent_request, content, session_attributes)    
            

        # ì²˜ë¦¬í•  ìˆ˜ ì—†ëŠ” íƒœìŠ¤í¬ ìœ í˜•ì´ ì…ë ¥ëœ ê²½ìš°
        # raise ValueError(f"Unsupported task type: {task_type}")
        
    except Exception as e:
        logger.error('Exception: %s', e, exc_info=True)






def fallbackIntent(intent_request):
    try:
        session_attributes = get_session_attributes(intent_request)
        user_content = intent_request['inputTranscript']
        messages_prompt = [{"role": "system", "content": 'ë„ˆëŠ” ì‚¬ëŒë“¤ì—ê²Œ ë„ì›€ì´ ë˜ëŠ” ì¡°ìˆ˜ì•¼. ì§ˆë¬¸ì— ëŒ€í•´ í™•ì¸í•˜ê³  ì¹œì ˆí•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ë‹µë³€í•´ì¤˜.'}]
        messages_prompt.append({"role": "user", "content": user_content})
        
        logger.info('messages_prompt: %s', messages_prompt)
        response = openai.ChatCompletion.create(model="gpt-3.5-turbo", messages=messages_prompt)
        logger.info('fallbackIntent response: %s', response)
        
        text = response["choices"][0]["message"]["content"]
        message =  {
                'contentType': 'PlainText',
                'content': text
            }
        fulfillment_state = "Fulfilled"    
        return close(intent_request, session_attributes, fulfillment_state, message)
    except Exception as e:
        logger.error('Exception: %s', e, exc_info=True)


def dispatch(intent_request):
    intent_name = intent_request['sessionState']['intent']['name']
    response = None
    
    if intent_name == 'Reception':
        return Reception(intent_request)
    elif intent_name == 'FallbackIntent':
        return fallbackIntent(intent_request)

    raise Exception('Intent with name ' + intent_name + ' not supported')

def lambda_handler(event, context):
    logger.info('Event: %s', json.dumps(event))
    # logger.info('Function name: %s', context.function_name) #KBSEC
    
    response = dispatch(event)
    return response

# def lambda_handler(event, context):
#     # TODO: í”„ë¡œê·¸ë¨ ë¡œì§ì„ ì—¬ê¸°ì— ì‘ì„±í•˜ì„¸ìš”.
    
#     return {
#         'statusCode': 200,
#         'body': json.dumps('Hello from Lambda!')
#     }

